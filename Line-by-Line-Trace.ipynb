{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Walkthrough\n",
    "The following takes a slow motion walk through the code. Run each cell below, one at a time, looking at the code before running it. Study it in fact. \n",
    "\n",
    "The walkthrough is in 3 parts:\n",
    "- Comments, imports, variables, etc. at the top of the module\n",
    "- The `parse_table_row()` function that comprises the bulk of the functionality\n",
    "- The `scrape_undergrad_course_booklet()` function that reads the Tabula-generated CSV file and applies the `parse_table_row()` function to each line\n",
    "\n",
    "Each section will first display the full source code and then run it in short snippets so we can examine variable settings (program state) along the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Definitional Code at the the Top of the File\n",
    "First, let's walk through the first few lines of code, up to the first function definition. \n",
    "\n",
    "<!-- Note: ever wondered how you show Python code in Markdown? See below. -->\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "File: course_schedules_tabula.py\n",
    "\n",
    "Created on Tue Dec  5 12:57:56 2017\n",
    "\n",
    "@author: chuntley\n",
    "\n",
    "A utility for extracting Fairfield U course data from text scraped PDF files using tabula.\n",
    "Currently works for the Spring 2018 Course Booklet.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# A set of tags that appear in the Notes field of a course_spec string\n",
    "tags = {\n",
    "  'CLRC':'Creative Life Residential College',\n",
    "  'CORN':'Cornerstone Course',\n",
    "  'HYBD':'Hybrid Course',\n",
    "  'IGRC':'Ignatian Residential College',\n",
    "  'RCOL':'Residential Colleges',\n",
    "  'SERO':'Service Learning Option',\n",
    "  'RNNU':'RN to BSN Students Only',\n",
    "  'SJRC':'Service for Justice Residential College',\n",
    "  'SDNU':'Second Degree Nurses Only',\n",
    "  'UDIV':'U.S. Diversity',\n",
    "  'SERL':'Service Learning',\n",
    "  'WDIV':'World Diversity'\n",
    "}\n",
    "\n",
    "# A set of regular expressions (regex patterns) to use to extract data fields from a table row\n",
    "flds = {\n",
    "    'crn':re.compile('(^[0-9]+)'),\n",
    "    'catalog_id':re.compile('(^[A-Z]+ [0-9,A-Z]+)'),\n",
    "    'section':re.compile('(^[0-9,A-Z]+)'),\n",
    "    'credits':re.compile('(^[0-9])'),\n",
    "    'timecode':re.compile('(TBA|[Bb]y [Aa]rrangement|[Oo]nline|[MTWRFSU]+ [0-9]{4}-[0-9]{4}[PpAa][Mm])'),\n",
    "    'tags':re.compile('('+'|'.join(tags.keys())+')'),\n",
    "    'instructor':re.compile('(.+)'),\n",
    "    'title':re.compile('(.+)')\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Line by Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The very top of the file is for execution notes, comments, etc. Leaving this stuff out is considered extremely unprofessional.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This particular module was designed to be run as a script from the command line. By convention, the first line then needs to tell the (command line interface) shell how it expects to be run. Below we are using the `python3` interpreter in the `/usr/bin/env` folder on MacOS X. (We'd have to modify it for other computer setups.) Note how the two lines are a comment in Python? The code is never executed by Python. Thats what the shell is for.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: course_schedules_tabula.py\n",
    "\n",
    "Created on Tue Dec  5 12:57:56 2017\n",
    "\n",
    "@author: chuntley\n",
    "\n",
    "A utility for extracting Fairfield U course data from text scraped PDF files using tabula.\n",
    "Currently works for the Spring 2018 Course Booklet.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports come just after the comments so the imported code can be used farter down in the file.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re     # regular expressions\n",
    "import csv    # csv file I/O\n",
    "import json   # JSON data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sometimes we will need to create constants or configuration variables used by the rest of the code. Like the imports, always define constants and config variables near the top of the file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of tags that appear in the Notes field of the course booklet\n",
    "tags = {\n",
    "  'CLRC':'Creative Life Residential College',\n",
    "  'CORN':'Cornerstone Course',\n",
    "  'HYBD':'Hybrid Course',\n",
    "  'IGRC':'Ignatian Residential College',\n",
    "  'RCOL':'Residential Colleges',\n",
    "  'SERO':'Service Learning Option',\n",
    "  'RNNU':'RN to BSN Students Only',\n",
    "  'SJRC':'Service for Justice Residential College',\n",
    "  'SDNU':'Second Degree Nurses Only',\n",
    "  'UDIV':'U.S. Diversity',\n",
    "  'SERL':'Service Learning',\n",
    "  'WDIV':'World Diversity'\n",
    "}\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This next snippet defines a regular expression for each column of the CSV file.** Don't know what a regular expression is? [RTFM](https://docs.python.org/3.7/library/re.html) or try [this tutorial](https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of regular expressions (regex patterns) to use to extract data fields from a table row\n",
    "flds = {\n",
    "    'crn':re.compile('(^[0-9]+)'),\n",
    "    'catalog_id':re.compile('(^[A-Z]+ [0-9,A-Z]+)'),\n",
    "    'section':re.compile('(^[0-9,A-Z]+)'),\n",
    "    'credits':re.compile('(^[0-9])'),\n",
    "    'timecode':re.compile('(TBA|[Bb]y [Aa]rrangement|[Oo]nline|[MTWRFSU]+ [0-9]{4}-[0-9]{4}[PpAa][Mm])'),\n",
    "    'tags':re.compile('('+'|'.join(tags.keys())+')'),\n",
    "    'instructor':re.compile('(.+)'),\n",
    "    'title':re.compile('(.+)')\n",
    "}\n",
    "flds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: the `parse_table_row()` function\n",
    "\n",
    "**The `parse_table_row()` function does the actual cleanup of the data. \n",
    "\n",
    "Note the use of a triple-quoted docstring to document what the function does. We can include lots of things in docstring comments (e.g., parameter definitions, assumptions, outputs, etc.) but in this case it's just a single line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table_row(row):\n",
    "    ''' Parse one row of tabula data; each row is a column-wise list of strings'''\n",
    "\n",
    "    course_spec = {}\n",
    "\n",
    "    # Deal with extra timecodes on rows by themselves\n",
    "    if not row[0]:\n",
    "        unparsed = ' '.join(row)\n",
    "        # use a regex to extract the timecode\n",
    "        course_spec['timecodes'] = flds['timecode'].findall(unparsed)\n",
    "\n",
    "        # return a partial course_spec with just the timecode\n",
    "        return course_spec\n",
    "\n",
    "    # What follows handles a typical table row exported from tabula\n",
    "\n",
    "    # Parse out the easier columns that always seem to work in tabula\n",
    "    course_spec['crn'] = int(row[0])\n",
    "    course_spec['catalog_id'] = row[1] + ' ' + row[2]\n",
    "    course_spec['section'] = row[3]\n",
    "    course_spec['title'] = row[4]\n",
    "\n",
    "    # Parse out the trickier columns that seem to merge awkwardly in tabula.\n",
    "    # The logic below applies regular expressions to an unparsed string.\n",
    "    # For each column:\n",
    "    #   1. use a regex to extract data from the unparsed string;\n",
    "    #   2. remove the extracted data from the unparsed string\n",
    "    unparsed = ' '.join(row[5:]) # create a string of columns\n",
    "\n",
    "    credits = flds['credits'].findall(unparsed)\n",
    "    course_spec['credits'] = int(credits[0]) if credits else 0 # number of credits\n",
    "    unparsed = flds['credits'].sub('',unparsed)\n",
    "\n",
    "    course_spec['tags'] = flds['tags'].findall(unparsed) # list of tags\n",
    "    unparsed = flds['tags'].sub('',unparsed)\n",
    "\n",
    "    course_spec['timecodes']=flds['timecode'].findall(unparsed) # list of timecodes\n",
    "    unparsed = flds['timecode'].sub('',unparsed)\n",
    "\n",
    "    course_spec['instructor']=unparsed.strip() # remainder, minus extra whitespace\n",
    "\n",
    "    return course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Line by Line Trace\n",
    "**Rather than run the function directly, let's run it's body line by line for a couple of different rows of data:** \n",
    "- `[\"35712\",\"MU\",\"0120\",\"01\",\"History of Hip Hop\",\"3 MR 0200-0250pm\",\"\",\"Yezee, I\",\"UDIV HYBD\"]`\n",
    "- `[\"\",\"\",\"\",\"\",\"\",\"W\",\"1000-1050am\",\"\",\"\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row 1: `parse_table_row([\"35712\",\"MU\",\"0120\",\"01\",\"History of Hip Hop\",\"3 MR 0200-0250pm\",\"\",\"Yezee, I\",\"UDIV HYBD\"])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The local variable below is meant to be equivalent to calling the function. It's not in the module code.\n",
    "row = [\"35712\",\"MU\",\"0120\",\"01\",\"History of Hip Hop\",\"3 MR 0200-0250pm\",\"\",\"Yezee, I\",\"UDIV HYBD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_spec = {}\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This conditional deals with a special case. If the special case applies then the function returns immediately without running the code below this block. This \"short-circuit\" technique is used a lot in systems programming to guard against so-called \"corner-case\" bugs.**\n",
    "\n",
    "In this case the special case does not apply so the code has not effect.  \n",
    "\n",
    "Note: Since we are in a cell, not a function, the `return` statement has been commented out in our snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with extra timecodes on rows by themselves\n",
    "if not row[0]:\n",
    "    unparsed = ' '.join(row)\n",
    "    # use a regex to extract the timecode\n",
    "    course_spec['timecodes'] = flds['timecode'].findall(unparsed)\n",
    "    \n",
    "    # return a partial course_spec with just the timecode\n",
    "    # return course_spec\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The rest of the function handles the normal case, where it builds up a dictionary  based on the columns/fields expected in the CSV file.**\n",
    "\n",
    "The first few columns are easy. Just take them directly from the list of srings in the `row` variable, formatting the data to what it needs as it goes along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out the easier columns that always seem to work in tabula\n",
    "course_spec['crn'] = int(row[0])\n",
    "course_spec['catalog_id'] = row[1] + ' ' + row[2]\n",
    "course_spec['section'] = row[3]\n",
    "course_spec['title'] = row[4]\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With the easy columns parsed out, we can now move on to the hard ones where the column breaks are possibly wrong. For this we'll need to use regular expressions to pluck them out of the line of input.**\n",
    "\n",
    "Also, since the column breaks cant be trusted anyway, the code starts by reassembling the original line of input for these last few columns. \n",
    "\n",
    "**For the remaining code `unparsed` always has the part of the input string that has not been parsed yet. We will truncate it as we go along.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out the trickier columns that seem to merge awkwardly in tabula.\n",
    "# The logic below applies regular expressions to an unparsed string.\n",
    "# For each column:\n",
    "#   1. use a regex to extract data from the unparsed string;\n",
    "#   2. remove the extracted data from the unparsed string\n",
    "unparsed = ' '.join(row[5:]) # create a string of columns\n",
    "unparsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now for the regular expressions. The `flds` dict is defined near the top of the file. Each dictionary item is a regular expression saying what data in that column is supposed to look like.** \n",
    "The line below applies the pattern `(^[0-9])` to extract any single-digit numbers at the front of the string. The result of calling the `.findall()` method is always a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " credits = flds['credits'].findall(unparsed)\n",
    " credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once the credits has been extracted, it is converted to an integer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_spec['credits'] = int(credits[0]) if credits else 0 # number of credits\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After the credits are extracted and insterted into dictionary, we update `unparsed` to reflect that we extracted data from it. Note the code chopped off the '3' from the head of the string. The remainder needs to be parsed.\n",
    "\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unparsed = flds['credits'].sub('',unparsed)\n",
    "unparsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_spec['tags'] = flds['tags'].findall(unparsed) # list of tags\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unparsed = flds['tags'].sub('',unparsed)\n",
    "unparsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_spec['timecodes']=flds['timecode'].findall(unparsed) # list of timecodes\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unparsed = flds['timecode'].sub('',unparsed)\n",
    "unparsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_spec['instructor']=unparsed.strip() # remainder, minus extra whitespace\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row 2: `parse_table_row([\"\",\"\",\"\",\"\",\"\",\"W\",\"1000-1050am\",\"\",\"\"])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A local variable to account for the row function parameter\n",
    "row = [\"\",\"\",\"\",\"\",\"\",\"W\",\"1000-1050am\",\"\",\"\"]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_spec = {}\n",
    "if not row[0]:\n",
    "    unparsed = ' '.join(row)\n",
    "    # use a regex to extract the timecode\n",
    "    course_spec['timecodes'] = flds['timecode'].findall(unparsed)\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function returns immediately in this case, so there is nothing more to trace.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: The `scrape_undergrad_course_booklet()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_undergrad_course_booklet(filename):\n",
    "    ''' Parse a course booklet that has been exported as a CSV from Tabula.'''\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        linereader = csv.reader(csvfile)\n",
    "        course_specs =[]\n",
    "        for row in linereader:\n",
    "            if not row[0].startswith('CRN'):\n",
    "                course_spec = parse_table_row(row)\n",
    "                if 'crn' in course_spec:\n",
    "                    # add the new course_spec\n",
    "                    course_specs += [course_spec]\n",
    "                elif 'timecodes' in course_spec:\n",
    "                    # merge timecode into last course_spec\n",
    "                    course_specs[-1]['timecodes'] += course_spec['timecodes']\n",
    "    return {'course_offerings':course_specs,'tags':tags}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 Line by Line\n",
    "**As with the previous function, we're just going to step through the meat of the function body for the two rows of CSV data. Assume that we are reading a CSV file with our two test rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('test_data.csv', newline='') as csvfile:\n",
    "        linereader = csv.reader(csvfile)\n",
    "        course_specs =[]\n",
    "        for row in linereader:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets take each (non-header) row in turn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['35712', 'MU', '0120', '01', 'History of Hip Hop', '3 MR 0200-0250pm', '', 'Yezee', ' I', 'UDIV HYBD']\n",
    "import course_schedules_tabula\n",
    "course_spec = course_schedules_tabula.parse_table_row(row)\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great, that matches what we already have! Now let's update course_specs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'crn' in course_spec:\n",
    "    # add the new course_spec\n",
    "    course_specs += [course_spec]\n",
    "elif 'timecodes' in course_spec:\n",
    "    # merge timecode into last course_spec\n",
    "    course_specs[-1]['timecodes'] += course_spec['timecodes']\n",
    "course_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With the first row processed, let's try to second row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['', '', '', '', '', 'W', '1000-1050am', '', '']\n",
    "course_spec = parse_table_row(row)\n",
    "course_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'crn' in course_spec:\n",
    "    # add the new course_spec\n",
    "    course_specs += [course_spec]\n",
    "elif 'timecodes' in course_spec:\n",
    "    # merge timecode into last course_spec\n",
    "    course_specs[-1]['timecodes'] += course_spec['timecodes']\n",
    "course_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_schedules_tabula.scrape_undergrad_course_booklet('tabula-201801CourseBooklet.csv')['course_offerings']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
